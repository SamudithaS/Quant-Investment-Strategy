{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd6f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded company features: (44, 7)\n",
      "Combined feature matrix: (44, 13)\n",
      "Scoring features of shape: (44, 13)\n",
      "                 score\n",
      "trades_CCS    0.977273\n",
      "trades_COMBN  0.295455\n",
      "trades_COMBX  0.340909\n",
      "trades_DFCC   0.534091\n",
      "trades_DIAL   0.034091\n"
     ]
    }
   ],
   "source": [
    "# quant_scoring.py\n",
    "# Enhanced ML pipeline: scores CSE companies by trading data + macroeconomic indicators\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_DIR = \"SPSL20/\"          # folder with per-company CSVs\n",
    "MACRO_FILES = {\n",
    "    'gdp_growth': 'GDP growth.csv',\n",
    "    'gdp_per_capita': 'GDP per Capita.csv',\n",
    "    'inflation': 'Inflation.csv'\n",
    "}\n",
    "FEATURE_COLS = [\n",
    "    'mean_return', 'volatility', 'sharpe_ratio', 'max_drawdown',\n",
    "    'momentum_20d', 'volume_change', 'turnover_change'\n",
    "]\n",
    "\n",
    "# --- Utility ---\n",
    "def clean_numeric_series(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "# --- Company Data Loader ---\n",
    "def load_and_process(file_path: str) -> pd.Series:\n",
    "    df = pd.read_csv(file_path, parse_dates=['Trade Date'], dayfirst=True, dtype=str)\n",
    "    for col in ['Open (Rs.)','High (Rs.)','Low (Rs.)','Close (Rs.)',\n",
    "                'TradeVolume','ShareVolume','Turnover (Rs.)']:\n",
    "        df[col] = clean_numeric_series(df[col])\n",
    "    df.sort_values('Trade Date', inplace=True)\n",
    "    df['return'] = df['Close (Rs.)'].pct_change()\n",
    "\n",
    "    # Calculate metrics\n",
    "    mean_return = df['return'].mean()\n",
    "    volatility = df['return'].std()\n",
    "    sharpe_ratio = (mean_return/volatility)*np.sqrt(252) if volatility else 0\n",
    "    cum = (1+df['return']).cumprod()\n",
    "    draw = cum / cum.cummax() - 1\n",
    "    max_dd = draw.min()\n",
    "    momentum = (df['Close (Rs.)'].iloc[-1] / df['Close (Rs.)'].iloc[-21] - 1) if len(df)>=21 else np.nan\n",
    "\n",
    "    if len(df)>=40:\n",
    "        vol20 = df['ShareVolume'].iloc[-20:].mean()\n",
    "        vol40 = df['ShareVolume'].iloc[-40:-20].mean()\n",
    "        toc20 = df['Turnover (Rs.)'].iloc[-20:].mean()\n",
    "        toc40 = df['Turnover (Rs.)'].iloc[-40:-20].mean()\n",
    "        vol_change = (vol20/vol40 - 1) if vol40 else np.nan\n",
    "        turn_change = (toc20/toc40 - 1) if toc40 else np.nan\n",
    "    else:\n",
    "        vol_change = turn_change = np.nan\n",
    "\n",
    "    return pd.Series([\n",
    "        mean_return, volatility, sharpe_ratio, max_dd,\n",
    "        momentum, vol_change, turn_change\n",
    "    ], index=FEATURE_COLS)\n",
    "\n",
    "# --- Macroeconomic Loader ---\n",
    "def load_macro_series(path: str) -> pd.Series:\n",
    "    if not os.path.isfile(path):\n",
    "        raise FileNotFoundError(f\"Macro file not found: {path}\")\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    years = df.iloc[0].astype(int).tolist()\n",
    "    values = df.iloc[1].astype(float).tolist()\n",
    "    return pd.Series(data=values, index=years)\n",
    "\n",
    "# --- Build Features ---\n",
    "def build_feature_matrix() -> pd.DataFrame:\n",
    "    # Company features\n",
    "    files = glob.glob(os.path.join(DATA_DIR, '*.csv')) + glob.glob(os.path.join(DATA_DIR, '*.CSV'))\n",
    "    if not files:\n",
    "        raise ValueError(f\"No CSV files found in data directory '{DATA_DIR}'\")\n",
    "\n",
    "    feats, tickers = [], []\n",
    "    for f in files:\n",
    "        try:\n",
    "            feats.append(load_and_process(f))\n",
    "            tickers.append(os.path.splitext(os.path.basename(f))[0])\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {f}: {e}\")\n",
    "\n",
    "    company_df = pd.DataFrame(feats, index=tickers)\n",
    "    print(f\"Loaded company features: {company_df.shape}\")\n",
    "\n",
    "    # Macro features\n",
    "    macro_data = {}\n",
    "    for name, path in MACRO_FILES.items():\n",
    "        try:\n",
    "            series = load_macro_series(path)\n",
    "        except Exception as e:\n",
    "            raise\n",
    "        latest = series.index.max()\n",
    "        macro_data[f\"{name}_latest\"] = series[latest]\n",
    "        macro_data[f\"{name}_yoy\"] = (series[latest]/series.get(latest-1, np.nan) - 1)\n",
    "\n",
    "    # Combine\n",
    "    macro_df = pd.DataFrame([macro_data] * len(company_df), index=company_df.index)\n",
    "    full_df = pd.concat([company_df, macro_df], axis=1)\n",
    "    print(f\"Combined feature matrix: {full_df.shape}\")\n",
    "    return full_df\n",
    "\n",
    "# --- Scoring ---\n",
    "def compute_scores(feature_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(f\"Scoring features of shape: {feature_df.shape}\")\n",
    "    if feature_df.empty or feature_df.shape[1] == 0:\n",
    "        raise ValueError(f\"Empty feature DataFrame {feature_df.shape}, check data inputs.\")\n",
    "    # Impute & scale\n",
    "    feature_df = feature_df.fillna(feature_df.mean())\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(feature_df)\n",
    "\n",
    "    # PCA -> score\n",
    "    pca = PCA(n_components=1)\n",
    "    raw = pca.fit_transform(scaled).flatten()\n",
    "    score_pct = pd.Series(raw, index=feature_df.index).rank(pct=True)\n",
    "    return pd.DataFrame({'score': score_pct})\n",
    "\n",
    "# --- Main ---\n",
    "def main():\n",
    "    features = build_feature_matrix()\n",
    "    scores = compute_scores(features)\n",
    "    scores.to_csv('SPSL20 company_scores_with_macro.csv')\n",
    "    print(scores.head())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910772fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
