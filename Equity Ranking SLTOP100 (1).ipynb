{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf563b3c",
   "metadata": {},
   "source": [
    "## Equity Ranking and Scoring of top 100 Market cap companies listed in CSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb17730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1b9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory of trading data\n",
    "DATA_DIR = \"SLTOP100/\"\n",
    "\n",
    "#Feature columns to compute\n",
    "FEATURES = [\n",
    "    'mean_return',          # Average daily return\n",
    "    'volatility',           # Standard deviation of daily returns\n",
    "    'sharpe_ratio',         # Risk-adjusted return (mean / volatility)\n",
    "    'max_drawdown',         # Maximum drawdown\n",
    "    'momentum_20d',         # 20-day momentum\n",
    "    'volume_change',        # Recent volume change\n",
    "    'turnover_change'       # Recent turnover change\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d933bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing & feature computing\n",
    "#Removing commas and convert numeric strings into floats\n",
    "def clean_numeric_series(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "#Load a single company's data\n",
    "def load_and_process(file_path: str) -> pd.Series:\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        parse_dates=['Trade Date'],\n",
    "        dayfirst=True,\n",
    "        dtype=str\n",
    "    )\n",
    "\n",
    "    #Clean numeric columns\n",
    "    for col in ['Open (Rs.)', 'High (Rs.)', 'Low (Rs.)', 'Close (Rs.)',\n",
    "                'TradeVolume', 'ShareVolume', 'Turnover (Rs.)']:\n",
    "        df[col] = clean_numeric_series(df[col])\n",
    "\n",
    "    #Sort by date\n",
    "    df = df.sort_values('Trade Date').reset_index(drop=True)\n",
    "\n",
    "    #Compute daily returns\n",
    "    df['return'] = df['Close (Rs.)'].pct_change()\n",
    "\n",
    "    #Feature: mean daily return\n",
    "    mean_return = df['return'].mean()\n",
    "\n",
    "    #Feature: volatility (std of returns)\n",
    "    volatility = df['return'].std()\n",
    "\n",
    "    #Feature: sharpe ratio (annualized)\n",
    "    sharpe_ratio = (mean_return / volatility) * np.sqrt(252) if volatility != 0 else 0\n",
    "\n",
    "    #Feature: max drawdown\n",
    "    cum_returns = (1 + df['return']).cumprod()\n",
    "    rolling_max = cum_returns.cummax()\n",
    "    drawdown = cum_returns / rolling_max - 1\n",
    "    max_drawdown = drawdown.min()\n",
    "\n",
    "    #Feature: momentum (change over 20 trading days)\n",
    "    if len(df) >= 21:\n",
    "        momentum_20d = df['Close (Rs.)'].iloc[-1] / df['Close (Rs.)'].iloc[-21] - 1\n",
    "    else:\n",
    "        momentum_20d = np.nan\n",
    "\n",
    "    #Feature: recent volume change (last 20 days vs prior 20 days)\n",
    "    if len(df) >= 40:\n",
    "        vol_recent = df['ShareVolume'].iloc[-20:].mean()\n",
    "        vol_prior = df['ShareVolume'].iloc[-40:-20].mean()\n",
    "        volume_change = (vol_recent / vol_prior - 1) if vol_prior != 0 else np.nan\n",
    "    else:\n",
    "        volume_change = np.nan\n",
    "\n",
    "    #Feature: recent turnover change (20-day)\n",
    "    if len(df) >= 40:\n",
    "        turn_recent = df['Turnover (Rs.)'].iloc[-20:].mean()\n",
    "        turn_prior = df['Turnover (Rs.)'].iloc[-40:-20].mean()\n",
    "        turnover_change = (turn_recent / turn_prior - 1) if turn_prior != 0 else np.nan\n",
    "    else:\n",
    "        turnover_change = np.nan\n",
    "\n",
    "    return pd.Series([\n",
    "        mean_return,\n",
    "        volatility,\n",
    "        sharpe_ratio,\n",
    "        max_drawdown,\n",
    "        momentum_20d,\n",
    "        volume_change,\n",
    "        turnover_change\n",
    "    ], index=FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad33bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the feature DataFrame\n",
    "def build_feature_matrix(data_dir: str) -> pd.DataFrame:\n",
    "    all_files = glob.glob(os.path.join(data_dir, '*.csv'))\n",
    "    feature_list = []\n",
    "    tickers = []\n",
    "\n",
    "    for file_path in all_files:\n",
    "        try:\n",
    "            features = load_and_process(file_path)\n",
    "            ticker = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            feature_list.append(features)\n",
    "            tickers.append(ticker)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    feature_df = pd.DataFrame(feature_list, index=tickers)\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cfa3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing equity scores\n",
    "def compute_scores(feature_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    #Handling missing values\n",
    "    feature_df = feature_df.fillna(feature_df.mean())\n",
    "\n",
    "    #Standardizing\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(feature_df)\n",
    "\n",
    "    #PCA: first principal component as score\n",
    "    pca = PCA(n_components=1)\n",
    "    scores = pca.fit_transform(scaled)\n",
    "\n",
    "    #Higher scores = better performance\n",
    "    score_df = pd.DataFrame(scores, index=feature_df.index, columns=['score'])\n",
    "    score_df['score'] = score_df['score'].rank(pct=True) \n",
    "\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa16619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix built with shape: (100, 7)\n",
      "             score\n",
      "trades_AAIC   0.88\n",
      "trades_ABL    0.97\n",
      "trades_ACL    0.73\n",
      "trades_AEL    0.83\n",
      "trades_AHPL   0.21\n",
      "Scores of SLTOP100 saved to SLTOP100 company_scores.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #Building features\n",
    "    features = build_feature_matrix(DATA_DIR)\n",
    "    print(\"Feature matrix built with shape:\", features.shape)\n",
    "\n",
    "    #Computing scores\n",
    "    scores = compute_scores(features)\n",
    "    print(scores.head())\n",
    "\n",
    "    #Save scores to CSV\n",
    "    scores.to_csv('SLTOP100 company_scores.csv')\n",
    "    print(\"Scores of SLTOP100 saved to SLTOP100 company_scores.csv\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08b42a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5685f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
