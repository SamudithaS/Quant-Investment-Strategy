{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3667a8d",
   "metadata": {},
   "source": [
    "## Government security rate forecasting and ladder optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6ce292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from statsmodels.tsa.api import VAR\n",
    "from scipy.optimize import minimize\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f26ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data configuration\n",
    "TBILL_FILE = 'tbill.csv'\n",
    "TBOND_FILE = 'tbonds.csv'\n",
    "FORECAST_STEPS = 12       #Number of weeks ahead to forecast\n",
    "gamma = 1.0               #Risk aversion parameter for ladder optimization\n",
    "MODEL_TYPE = 'VAR'        #VAR or LSTM\n",
    "LSTM_EPOCHS = 50\n",
    "LSTM_BATCH = 16\n",
    "LSTM_LOOKBACK = 24        #Past weeks for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7615ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean numeric series\n",
    "def clean_numeric(s: pd.Series) -> pd.Series:\n",
    "    num = pd.to_numeric(s.astype(str).str.replace(',', ''), errors='coerce')\n",
    "    return num.ffill().bfill()\n",
    "\n",
    "#Date column\n",
    "def find_date_column(df: pd.DataFrame) -> str:\n",
    "    for col in df.columns:\n",
    "        key = col.lower()\n",
    "        if 'week' in key or 'date' in key or 'time' in key:\n",
    "            return col\n",
    "    return df.columns[0]\n",
    "\n",
    "#T BILL data\n",
    "def load_tbill(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    date_col = find_date_column(df)\n",
    "    df[date_col] = pd.to_datetime(df[date_col], dayfirst=False, errors='coerce')\n",
    "    df.set_index(date_col, inplace=True)\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.sort_index().resample('W').ffill()\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = clean_numeric(df[col]) / 100.0\n",
    "    return df\n",
    "\n",
    "#T BONDS data\n",
    "def load_tbonds(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    date_col = find_date_column(df)\n",
    "    df[date_col] = pd.to_datetime(df[date_col], dayfirst=False, errors='coerce')\n",
    "    df.set_index(date_col, inplace=True)\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    df = df.sort_index().resample('W').ffill()\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = clean_numeric(df[col]) / 100.0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39e2b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing LSTM data\n",
    "def prepare_lstm_data(df: pd.DataFrame, lookback: int, forecast_steps: int):\n",
    "    n_obs, n_feats = df.shape\n",
    "    min_length = lookback + forecast_steps\n",
    "    if n_obs < min_length:\n",
    "        raise ValueError(f\"Insufficient data: need at least {min_length} rows, got {n_obs}.\")\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(df)\n",
    "    X, y = [], []\n",
    "    for i in range(n_obs - min_length + 1):\n",
    "        X.append(scaled[i:i+lookback])\n",
    "        y.append(scaled[i+lookback:i+min_length])\n",
    "    return np.array(X), np.array(y), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c8fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rate forecasting via VAR\n",
    "def forecast_var(df: pd.DataFrame, steps: int) -> pd.DataFrame:\n",
    "    n_obs, n_vars = df.shape\n",
    "    dynamic_maxlags = min(4, max((n_obs - 1) // (n_vars + 1), 1))\n",
    "    model = VAR(df)\n",
    "    try:\n",
    "        res = model.fit(maxlags=dynamic_maxlags, ic='aic')\n",
    "    except Exception:\n",
    "        res = model.fit(maxlags=dynamic_maxlags)\n",
    "    lag = res.k_ar\n",
    "    out = res.forecast(df.values[-lag:], steps)\n",
    "    idx = pd.date_range(df.index[-1] + timedelta(weeks=1), periods=steps, freq='W')\n",
    "    return pd.DataFrame(out, index=idx, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5904dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rate forecasting via LSTM\n",
    "def forecast_lstm(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    X, y, scaler = prepare_lstm_data(df, LSTM_LOOKBACK, FORECAST_STEPS)\n",
    "    X_train, y_train = X[:-1], y[:-1]\n",
    "    n_steps, n_feats = X_train.shape[1], X_train.shape[2]\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(n_steps, n_feats)),\n",
    "        Dense(n_feats * FORECAST_STEPS)\n",
    "    ])\n",
    "    model.compile('adam', 'mse')\n",
    "    model.fit(X_train, y_train.reshape(len(y_train), -1), epochs=LSTM_EPOCHS,\n",
    "              batch_size=LSTM_BATCH, verbose=1)\n",
    "    pred = model.predict(X[-1][np.newaxis, ...])\n",
    "    out = pred.reshape(FORECAST_STEPS, n_feats)\n",
    "    inv = scaler.inverse_transform(out)\n",
    "    idx = pd.date_range(df.index[-1] + timedelta(weeks=1), periods=FORECAST_STEPS, freq='W')\n",
    "    return pd.DataFrame(inv, index=idx, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83fd3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ladder Optimization\n",
    "def optimize_ladder(forecast_df: pd.DataFrame, gamma: float = 1.0) -> pd.Series:\n",
    "    mu = forecast_df.mean().values\n",
    "    Sigma = forecast_df.cov().values\n",
    "    n = len(mu)\n",
    "    cons = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0,1)] * n\n",
    "    res = minimize(lambda w: -(w.dot(mu) - gamma * w.dot(Sigma).dot(w)),\n",
    "                   np.ones(n)/n, bounds=bounds, constraints=cons)\n",
    "    if not res.success:\n",
    "        raise RuntimeError('Optimization failed: ' + res.message)\n",
    "    return pd.Series(res.x, index=forecast_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dc524cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR model failed (x contains one or more constant columns. Column(s) 15, 31, 47, 63 are constant. Adding a constant with trend='c' is not allowed.); falling back to LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samudhitha\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2071\n",
      "Epoch 2/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0519\n",
      "Epoch 3/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0289\n",
      "Epoch 4/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0200\n",
      "Epoch 5/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0170\n",
      "Epoch 6/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0131\n",
      "Epoch 7/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0124\n",
      "Epoch 8/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0109\n",
      "Epoch 9/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0107\n",
      "Epoch 10/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0100\n",
      "Epoch 11/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0089\n",
      "Epoch 12/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0080\n",
      "Epoch 13/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0080\n",
      "Epoch 14/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0076\n",
      "Epoch 15/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0078\n",
      "Epoch 16/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0072\n",
      "Epoch 17/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0070\n",
      "Epoch 18/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0069\n",
      "Epoch 19/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0067\n",
      "Epoch 20/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0063\n",
      "Epoch 21/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058\n",
      "Epoch 22/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0062\n",
      "Epoch 23/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0060\n",
      "Epoch 24/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0057\n",
      "Epoch 25/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054\n",
      "Epoch 26/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059\n",
      "Epoch 27/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056\n",
      "Epoch 28/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053\n",
      "Epoch 29/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051\n",
      "Epoch 30/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0056\n",
      "Epoch 31/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052\n",
      "Epoch 32/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047\n",
      "Epoch 33/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052\n",
      "Epoch 34/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0050\n",
      "Epoch 35/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050\n",
      "Epoch 36/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051\n",
      "Epoch 37/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0045\n",
      "Epoch 38/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0048\n",
      "Epoch 39/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048\n",
      "Epoch 40/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048\n",
      "Epoch 41/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040\n",
      "Epoch 42/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043\n",
      "Epoch 43/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040\n",
      "Epoch 44/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0050\n",
      "Epoch 45/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042\n",
      "Epoch 46/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041\n",
      "Epoch 47/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043\n",
      "Epoch 48/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041\n",
      "Epoch 49/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036\n",
      "Epoch 50/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
      "Forecasted Rates (decimals):\n",
      "             91 days  182 days  364 days   02 year   03 year   04 year  \\\n",
      "2025-01-05  0.108021  0.123354  0.120638  0.121742  0.126869  0.119202   \n",
      "2025-01-12  0.113054  0.110168  0.107459  0.120737  0.126220  0.117838   \n",
      "2025-01-19  0.115343  0.109900  0.123453  0.119383  0.127941  0.118385   \n",
      "2025-01-26  0.119781  0.119828  0.110842  0.118623  0.126269  0.117154   \n",
      "2025-02-02  0.104589  0.111963  0.113443  0.119093  0.134015  0.113156   \n",
      "2025-02-09  0.107593  0.112010  0.108760  0.118958  0.126079  0.113346   \n",
      "2025-02-16  0.102516  0.111799  0.107258  0.116864  0.126812  0.114736   \n",
      "2025-02-23  0.105296  0.108108  0.108883  0.117845  0.129480  0.115601   \n",
      "2025-03-02  0.108122  0.113766  0.106194  0.117714  0.129047  0.109308   \n",
      "2025-03-09  0.100350  0.105579  0.116665  0.115480  0.126325  0.109747   \n",
      "2025-03-16  0.108624  0.100944  0.111581  0.113527  0.136056  0.106858   \n",
      "2025-03-23  0.106064  0.113803  0.115440  0.113695  0.129789  0.109980   \n",
      "\n",
      "             05 year   06 year   07 year   08 year   09 year   10 year  \\\n",
      "2025-01-05  0.133900  0.127466  0.151412  0.121612  0.126365  0.126544   \n",
      "2025-01-12  0.130243  0.126146  0.146209  0.122927  0.126222  0.127907   \n",
      "2025-01-19  0.132099  0.125276  0.140038  0.121176  0.126319  0.127303   \n",
      "2025-01-26  0.127881  0.126733  0.140197  0.124242  0.126627  0.125875   \n",
      "2025-02-02  0.132462  0.124564  0.139684  0.121772  0.126243  0.126697   \n",
      "2025-02-09  0.129897  0.124524  0.138788  0.121605  0.126273  0.126544   \n",
      "2025-02-16  0.129255  0.125148  0.139749  0.126837  0.126067  0.124705   \n",
      "2025-02-23  0.129889  0.124583  0.139653  0.126341  0.125553  0.126066   \n",
      "2025-03-02  0.136754  0.126959  0.139499  0.125893  0.125200  0.128846   \n",
      "2025-03-09  0.134879  0.125801  0.136408  0.126733  0.125167  0.126947   \n",
      "2025-03-16  0.131672  0.125813  0.138881  0.131594  0.125962  0.124548   \n",
      "2025-03-23  0.133377  0.125646  0.139466  0.121731  0.125732  0.124946   \n",
      "\n",
      "             12 year   15 year   20 year   30 year  \n",
      "2025-01-05  0.125224  0.143022  0.106297  0.141771  \n",
      "2025-01-12  0.124173  0.144325  0.106472  0.143308  \n",
      "2025-01-19  0.124319  0.145208  0.106418  0.121424  \n",
      "2025-01-26  0.125461  0.143961  0.106364  0.111436  \n",
      "2025-02-02  0.124142  0.145259  0.106621  0.117968  \n",
      "2025-02-09  0.124079  0.145437  0.106623  0.138294  \n",
      "2025-02-16  0.124693  0.143014  0.106853  0.101563  \n",
      "2025-02-23  0.125358  0.143227  0.107060  0.116639  \n",
      "2025-03-02  0.125501  0.143145  0.106939  0.112405  \n",
      "2025-03-09  0.126161  0.144441  0.106620  0.097643  \n",
      "2025-03-16  0.125246  0.143094  0.106750  0.143016  \n",
      "2025-03-23  0.125560  0.144360  0.106578  0.145189  \n",
      "\n",
      "Optimal Ladder Weights:\n",
      "91 days     4.365950e-17\n",
      "182 days    9.187965e-17\n",
      "364 days    0.000000e+00\n",
      "02 year     5.418780e-17\n",
      "03 year     0.000000e+00\n",
      "04 year     5.398101e-18\n",
      "05 year     2.225757e-16\n",
      "06 year     3.112771e-17\n",
      "07 year     0.000000e+00\n",
      "08 year     0.000000e+00\n",
      "09 year     1.789825e-16\n",
      "10 year     0.000000e+00\n",
      "12 year     0.000000e+00\n",
      "15 year     1.000000e+00\n",
      "20 year     0.000000e+00\n",
      "30 year     2.391270e-17\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Main execution with VAR or LSTM fallback\n",
    "def main():\n",
    "    tbill = load_tbill(TBILL_FILE)\n",
    "    tbond = load_tbonds(TBOND_FILE)\n",
    "    rates = pd.concat([tbill, tbond], axis=1).dropna()\n",
    "\n",
    "    #Forecasting\n",
    "    if MODEL_TYPE.upper() == 'VAR':\n",
    "        try:\n",
    "            forecast_df = forecast_var(rates, FORECAST_STEPS)\n",
    "        except Exception as e:\n",
    "            print(f\"VAR model failed ({e}); falling back to LSTM...\")\n",
    "            forecast_df = forecast_lstm(rates)\n",
    "    else:\n",
    "        forecast_df = forecast_lstm(rates)\n",
    "\n",
    "    print(f\"Forecasted Rates (decimals):\\n{forecast_df}\\n\")\n",
    "\n",
    "    #Ladder optimization\n",
    "    weights = optimize_ladder(forecast_df, gamma)\n",
    "    print(f\"Optimal Ladder Weights:\\n{weights}\")\n",
    "\n",
    "    #Saving results\n",
    "    forecast_df.to_csv(f'rates_forecast_{MODEL_TYPE}.csv')\n",
    "    weights.to_csv('ladder_weights.csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d49e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
